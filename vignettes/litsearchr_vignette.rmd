---
title: "Search term selection with litsearchr for an example systematic review of the effects of forest fragmentation on bird-insect interactions"

author: "Eliza M. Grames and Emily Hennessy"

date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Search term selection with litsearchr for an example systematic review of the effects of forest fragmentation on bird-insect interactions}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  fig.width = 6,
  fig.height = 6
)
```

## About the package  
The *litsearchr* package for R is designed to partially automate search term selection and writing search strategies for systematic reviews. This vignette demonstrates its utility through an example systematic review examining the effects of forest fragmentation on bird-insect interactions by demonstrating how the package: (1) Identifies potential keywords through the naive search input, (2) Builds a keyword co-occurence network to assist with building a more precise search strategy, (3) Uses a spline function to identify important changes in keyword importance, (4) Assists with grouping terms into concepts, and (5) Writes a Boolean search as a result of completion of the four previous steps.

## Write and conduct naive search
In our empirical example, we begin with a naive search intended to capture a set of relevant articles. Naive search terms: (fragment* AND forest* AND (bird* OR passeri*) AND insect*). We ran the search in Scopus and Zoological Record (Web of Science), exporting results in .ris and .txt, respectively. These exported search results are then imported to litsearchr using the *import_results* function and next deduplicated using the *remove_duplicates* function. In some cases, it is best to run the *remove_duplicates* function two or more times, for example starting with exact matches and moving on to fuzzy matching. 

```{r}
search_directory <- paste(system.file(package="synthesisr"), "/extdata/", sep="")

naiveimport <-
  litsearchr::import_results(directory = search_directory, verbose = TRUE)

naiveresults <-
  litsearchr::remove_duplicates(naiveimport, field = "title", method = "exact")
```



## 1. Identify potential keywords

Using the deduplicated records captured from the naive search, the *extract_terms* function will systematically extract all keywords from the reports that have been tagged as such in the record.

```{r}
rakedkeywords <-
  litsearchr::extract_terms(
    text = paste(naiveresults$title, naiveresults$abstract),
    method = "fakerake",
    min_freq = 2,
    ngrams = TRUE,
    n = 2,
    language = "English"
  )

taggedkeywords <-
  litsearchr::extract_terms(keywords = naiveresults$keywords, method = "tagged")
```



## 2. Build the keyword co-occurrence network
Using the results from *Step 1, Identify potential keywords*, a series of functions are next run to create a co-occurrence network. 


```{r}
all_keywords <- unique(append(taggedkeywords, rakedkeywords))

naivedfm <-
  litsearchr::create_dfm(elements = naiveresults$title, features = all_keywords)

naivegraph <-
  litsearchr::create_network(
    search_dfm = naivedfm,
    min_studies = 3,
    min_occurrences = 3
  )
```



## 3. Identify change points in keyword importance 
The keyword co-occurrence network can next be quantitatively assessed using a spline function for important changes in the level of importance of a particular keyword to the concept. This will help in making an efficient but comprehensive search. 

```{r}
cutoff <-
  litsearchr::find_cutoff(
    naivegraph,
    method = "cumulative",
    percent = .90,
    importance_method = "strength"
  )

reducedgraph <-
  litsearchr::reduce_graph(naivegraph, cutoff_strength = cutoff[1])

searchterms <- litsearchr::get_keywords(reducedgraph)
```

## 4. Group terms into concepts
Now that the important keywords for the search have been identified, they can be grouped into blocks to build the search strategy. For Boolean searches, terms are grouped into similar concept groups where they can be combined with "OR" statements and the separate blocks combined with "AND" statements.

In our example, all keywords that relate to forest fragmentation would be in a similar concept group (e.g., "fragmented landscape", "forest patch" etc.) while terms relating to insects and birds would be in their own concept groups.

We recommend saving the search terms to a .csv file, adding a new column called "group", and entering the group names in it. Terms that fit multiple concept groups can be added to both without changing the logic of the Boolean connections. For example, a term like "bird-insect interactions" would be added to both the insect and bird concept groups by labeling its group "insect, bird". Example code for this is below; it is commented out because it cannot be run without the .csv file.

```{r}

# write.csv(searchterms, "./search_terms.csv")
# manually group terms in the csv
# grouped_terms <- read.csv("./search_terms_grouped.csv")
# extract the fragmentation terms from the csv
# fragment_terms <- grouped_terms$term[which(stringr::str_detect(grouped_terms$group, "fragment"))]
# join together a list of manually generated fragmentation terms with the ones from the csv
# fragment <- unique(append(c("fragmentation", "area sensitivity", "patch size")), fragment_terms)

# repeat this for all concept groups
# then merge them into a list, using the code below as an example
# mysearchterms <- list(fragment, insects, birds)

```



## 5. Write Boolean searches
Once keywords are grouped into concept groups in a list, the *write_search* function can be used to write Boolean searches in multiple languages, ready for export and use in chosen databases. The example below demonstrates writing a search in English using the search terms.


```{r}
# note: these search terms are a shortened example of a full search for illustration purposes only
mysearchterms <-
  list(
    c(
      "forest fragmentation",
      "forest patch",
      "forest fragment",
      "forest remnant",
      "forest edge",
      "fragmentation",
      "landscape structure"
    ),
    c(
      "insect",
      "arthropod",
      "prey abundance",
      "food availability",
      "caterpillar"
    ),
    c(
      "bird",
      "passerine",
      "avian insectivores",
      "avian community",
      "bird assemblages"
    )
  )

my_search <-
  litsearchr::write_search(
    groupdata = mysearchterms,
    languages = "English",
    stemming = TRUE,
    closure = "none",
    exactphrase = TRUE,
    writesearch = FALSE,
    verbose = TRUE
  )

# when writing to a plain text file, the extra \ are required to render the * and " properly
# if copying straight from the console, simply find and replace them in a text editor
my_search

```


## 6. Check search strategy precision and recall

Save the titles of the articles you want to retrieve as a character vector called gold_standard. You may want to do this by reading in a .csv file or you can paste/type them out. In this example, we are only using three articles to test our search strategy, though normally you will want to use a longer list of articles identified through expert opinion and/or consulting the list of studies included in previous reviews related to the topic. We will write a simple search of these titles to run in the bibliographic databases we plan to use to check if they are indeed indexed and should be retrieved by our search terms. Any that are not indexed can be ignored for the following step.


```{r}
gold_standard <-
  c(
    "Avian top-down control affects invertebrate herbivory and sapling growth more strongly than overstorey species composition in temperate forest fragments",
    "Bird functional diversity enhances insectivory at forest edges: a transcontinental experiment",
    "Food shortage in small fragments: evidence from an area-sensitive passerine"
  )

title_search <- litsearchr::write_title_search(titles=gold_standard)

```

We then read in our full search results and compare them to our gold standard to determine which gold standard articles we retrieved. Note: in this case I am using the naive search results from earlier because this is just a demonstration and this is not a real systematic review, so I did not run the full searches. You will want to do this with your actual full search results. 

```{r}
search_directory <- paste(system.file(package="synthesisr"), "/extdata/", sep="")

retrieved_articles <- litsearchr::import_results(directory=search_directory)
retrieved_articles <- litsearchr::remove_duplicates(retrieved_articles, field="title", method="exact")

articles_found <- litsearchr::check_recall(true_hits = gold_standard,
                                           retrieved_articles = retrieved_articles$title)

articles_found
```

